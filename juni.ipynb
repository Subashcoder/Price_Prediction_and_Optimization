{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class AirbnbDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "class ROIPredictionCNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ROIPredictionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * (input_dim // 4), 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.replace('$', '').replace(',', '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Handle categorical variables\n",
    "    categorical_cols = ['neighbourhood_cleansed', 'room_type', 'property_type', 'host_response_time', 'bathrooms_text']\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    # Handle boolean columns\n",
    "    boolean_cols = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'has_availability', 'instant_bookable']\n",
    "    for col in boolean_cols:\n",
    "        df[col] = df[col].map({'t': 1, 'f': 0, True: 1, False: 0}).fillna(0).astype(int)\n",
    "    \n",
    "    # Select relevant numerical columns and clean them\n",
    "    numerical_cols = ['accommodates', 'host_listings_count', 'latitude', 'longitude', 'minimum_nights', 'availability_365', 'number_of_reviews', 'review_scores_rating']\n",
    "    for col in numerical_cols:\n",
    "        df[col] = df[col].apply(clean_numeric)\n",
    "    \n",
    "    # Handle price separately\n",
    "    df['price'] = df['price'].apply(clean_price).apply(clean_numeric)\n",
    "    \n",
    "    # Combine features\n",
    "    features = df[categorical_cols + boolean_cols + numerical_cols + ['price']]\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    features = features.dropna()\n",
    "    \n",
    "    # Calculate ROI (you may need to adjust this based on your specific ROI calculation)\n",
    "    df['roi'] = df['price'] * df['number_of_reviews'] / 365  # This is a simplified ROI calculation\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    return features_scaled, df.loc[features.index, 'roi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_features, batch_targets in train_loader:\n",
    "            batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs.squeeze(), batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in test_loader:\n",
    "            batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "            outputs = model(batch_features)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actual.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "    predictions = np.array(predictions).squeeze()\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    mse = np.mean((predictions - actual) ** 2)\n",
    "    print(f'Mean Squared Error: {mse:.4f}')\n",
    "    return predictions, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39696/2459219014.py:3: DtypeWarning: Columns (33,34,35,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"final_data.csv\", delimiter=';', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "neighbourhood_cleansed                           object\n",
      "room_type                                        object\n",
      "accommodates                                      int64\n",
      "property_type                                    object\n",
      "listing_url                                      object\n",
      "                                                 ...   \n",
      "calculated_host_listings_count_entire_homes     float64\n",
      "calculated_host_listings_count_private_rooms    float64\n",
      "calculated_host_listings_count_shared_rooms     float64\n",
      "reviews_per_month                               float64\n",
      "Month                                            object\n",
      "Length: 64, dtype: object\n",
      "\n",
      "First few rows:\n",
      "   neighbourhood_cleansed        room_type  accommodates       property_type  \\\n",
      "0                  Weston  Entire home/apt             8         Entire home   \n",
      "1                  Weston  Entire home/apt             8         Entire home   \n",
      "2                  Weston  Entire home/apt             5  Entire rental unit   \n",
      "3  Centennial Scarborough  Entire home/apt             5  Entire rental unit   \n",
      "4                  Weston  Entire home/apt             8         Entire home   \n",
      "\n",
      "                                       listing_url last_scraped  \\\n",
      "0            https://www.airbnb.com/rooms/16437963   2024-04-13   \n",
      "1            https://www.airbnb.com/rooms/36756889   2024-04-13   \n",
      "2            https://www.airbnb.com/rooms/37047977   2024-04-13   \n",
      "3  https://www.airbnb.com/rooms/940829105429920079   2024-04-12   \n",
      "4            https://www.airbnb.com/rooms/16437963   2024-08-08   \n",
      "\n",
      "            source                                               name  \\\n",
      "0      city scrape  Great 4 Bedroom w/Parking Toronto (Weston Vill...   \n",
      "1  previous scrape  2+1 bedroom / 8 guests+free Wifi/rent 7 seater...   \n",
      "2  previous scrape                                        Best Weston   \n",
      "3      city scrape                          Luxury basement apartment   \n",
      "4      city scrape  Great 4 Bedroom w/Parking Toronto (Weston Vill...   \n",
      "\n",
      "                               neighborhood_overview  \\\n",
      "0  This home is located in Weston Village a quain...   \n",
      "1  Our home is located in the historical Weston V...   \n",
      "2  Weston is beginning to look a lot different to...   \n",
      "3                                            UNKNOWN   \n",
      "4  This home is located in Weston Village a quain...   \n",
      "\n",
      "                                         picture_url  ...  \\\n",
      "0  https://a0.muscache.com/pictures/2ffcfad2-76be...  ...   \n",
      "1  https://a0.muscache.com/pictures/cc62d7ad-39ed...  ...   \n",
      "2  https://a0.muscache.com/pictures/5fc5036a-b9e1...  ...   \n",
      "3  https://a0.muscache.com/pictures/miso/Hosting-...  ...   \n",
      "4  https://a0.muscache.com/pictures/2ffcfad2-76be...  ...   \n",
      "\n",
      "   review_scores_location review_scores_value          license  \\\n",
      "0                    4.69                4.74  STR-2101-HCHKVJ   \n",
      "1                    0.00                0.00                0   \n",
      "2                    4.24                4.80                0   \n",
      "3                    5.00                5.00                0   \n",
      "4                    4.69                4.74  STR-2101-HCHKVJ   \n",
      "\n",
      "  instant_bookable calculated_host_listings_count  \\\n",
      "0                f                            2.0   \n",
      "1                t                            1.0   \n",
      "2                f                            1.0   \n",
      "3                t                            2.0   \n",
      "4                f                            2.0   \n",
      "\n",
      "   calculated_host_listings_count_entire_homes  \\\n",
      "0                                          2.0   \n",
      "1                                          1.0   \n",
      "2                                          1.0   \n",
      "3                                          2.0   \n",
      "4                                          2.0   \n",
      "\n",
      "   calculated_host_listings_count_private_rooms  \\\n",
      "0                                           0.0   \n",
      "1                                           0.0   \n",
      "2                                           0.0   \n",
      "3                                           0.0   \n",
      "4                                           0.0   \n",
      "\n",
      "  calculated_host_listings_count_shared_rooms reviews_per_month   Month  \n",
      "0                                         0.0               2.0   April  \n",
      "1                                         0.0               0.0   April  \n",
      "2                                         0.0               0.0   April  \n",
      "3                                         0.0               0.0   April  \n",
      "4                                         0.0               2.0  August  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "Epoch [10/100], Loss: 10.2315\n",
      "Epoch [20/100], Loss: 2.1834\n",
      "Epoch [30/100], Loss: 12.3110\n",
      "Epoch [40/100], Loss: 3.5472\n",
      "Epoch [50/100], Loss: 0.6285\n",
      "Epoch [60/100], Loss: 1.3952\n",
      "Epoch [70/100], Loss: 4.7929\n",
      "Epoch [80/100], Loss: 3.4246\n",
      "Epoch [90/100], Loss: 2.3082\n",
      "Epoch [100/100], Loss: 69.3222\n",
      "Mean Squared Error: 109.9912\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (248294) does not match length of index (248341)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(best_neighborhoods\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 39\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m predictions, actual \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Find the best neighborhoods\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_roi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mFloatTensor(features)\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     40\u001b[0m best_neighborhoods \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbourhood_cleansed\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_roi\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTop 5 Neighborhoods for ROI:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.9/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.9/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.9/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.9/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (248294) does not match length of index (248341)"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    df = pd.read_csv(\"final_data.csv\", delimiter=';', on_bad_lines='skip')\n",
    "    \n",
    "    # Print data types and first few rows\n",
    "    print(\"Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Preprocess data\n",
    "    features, targets = preprocess_data(df)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataset = AirbnbDataset(X_train, y_train)\n",
    "    test_dataset = AirbnbDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize the model\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = ROIPredictionCNN(input_dim).to(device)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 100\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions, actual = evaluate_model(model, test_loader)\n",
    "\n",
    "    # Find the best neighborhoods\n",
    "    df['predicted_roi'] = model(torch.FloatTensor(features).to(device)).cpu().detach().numpy()\n",
    "    best_neighborhoods = df.groupby('neighbourhood_cleansed')['predicted_roi'].mean().sort_values(ascending=False)\n",
    "    print(\"\\nTop 5 Neighborhoods for ROI:\")\n",
    "    print(best_neighborhoods.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
