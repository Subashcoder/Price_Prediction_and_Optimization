{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\AppData\\Local\\Temp\\ipykernel_11520\\389301483.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(r\"C:\\Users\\prabh\\Downloads\\airbnb_project\\data\\listing_oct_to_sept.csv\")\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\prabh\\Downloads\\airbnb_project\\data\\listing_oct_to_sept.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df.drop(['has_availability'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_scores_rating'] = df['review_scores_rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing values in host_since column with values from first review column\n",
    "df['host_since'] = df['host_since'].fillna(df['first_review'])\n",
    "# Show null values in host_since column\n",
    "print(df['host_since'].isnull().sum())\n",
    "\n",
    "# Drop entire row with null value in host_since column\n",
    "df = df.dropna(subset=['host_since'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['property'] = df['property_type'].astype('category').cat.codes\n",
    "df['neighbourhood'] = df['neighbourhood_cleansed'].astype('category').cat.codes\n",
    "#df['bathrooms'] = df['bathrooms_text'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numerical(df):\n",
    "    # Remove the dollar signs and commas, then convert to numeric (float64)\n",
    "    df['price'] = df['price'].str.replace('$', '', regex=False).str.replace(',', '', regex=False).astype(float)\n",
    "    return df\n",
    "\n",
    "df = to_numerical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average price\n",
    "average_price_df = df.groupby(['neighbourhood_cleansed', 'property_type', 'accommodates'])['price'].mean().reset_index()\n",
    "average_price_df = average_price_df.rename(columns={'price': 'average_price'})\n",
    "\n",
    "# Join with the original DataFrame\n",
    "df = pd.merge(df, average_price_df, on=['neighbourhood_cleansed', 'property_type', 'accommodates'], how='left')\n",
    "\n",
    "# Fill missing prices with the average\n",
    "df['price'] = df['price'].fillna(df['average_price'])\n",
    "\n",
    "# Drop the average price column\n",
    "df = df.drop('average_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numerical_values(df, columns):\n",
    "    for column in columns:\n",
    "        # Use apply with a lambda function to extract the numerical part from the string\n",
    "        df[column] = df[column].apply(lambda x: float(re.search(r'\\d+(?:\\.\\d+)?', str(x)).group()) if re.search(r'\\d+(?:\\.\\d+)?', str(x)) else None)\n",
    "    return df\n",
    "\n",
    "columns = ['bathrooms_text']\n",
    "df = extract_numerical_values(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average price\n",
    "average_bedrooms_df = df.groupby(['neighbourhood_cleansed', 'property_type', 'accommodates'])['bedrooms'].mean().reset_index()\n",
    "average_bedrooms_df = average_bedrooms_df.rename(columns={'bedrooms': 'average_bedrooms'})\n",
    "\n",
    "# Join with the original DataFrame\n",
    "df = pd.merge(df, average_bedrooms_df, on=['neighbourhood_cleansed', 'property_type', 'accommodates'], how='left')\n",
    "\n",
    "# Fill missing prices with the average\n",
    "df['bedrooms'] = df['bedrooms'].fillna(df['average_bedrooms'])\n",
    "\n",
    "# Drop the average price column\n",
    "df = df.drop('average_bedrooms', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average beds\n",
    "average_beds_df = df.groupby(['neighbourhood_cleansed', 'property_type', 'accommodates'])['beds'].mean().reset_index()\n",
    "average_beds_df = average_beds_df.rename(columns={'beds': 'average_beds'})\n",
    "\n",
    "# Join with the original DataFrame\n",
    "df = pd.merge(df, average_beds_df, on=['neighbourhood_cleansed', 'property_type', 'accommodates'], how='left')\n",
    "\n",
    "# Fill missing beds with the average\n",
    "df['beds'] = df['beds'].fillna(df['average_beds'])\n",
    "\n",
    "# Drop the average beds column\n",
    "df = df.drop('average_beds', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average bathrooms_text\n",
    "average_bathrooms_text_df = df.groupby(['neighbourhood_cleansed', 'property_type', 'accommodates'])['bathrooms_text'].mean().reset_index()\n",
    "average_bathrooms_text_df = average_bathrooms_text_df.rename(columns={'bathrooms_text': 'average_bathrooms_text'})\n",
    "\n",
    "# Join with the original DataFrame\n",
    "df = pd.merge(df, average_bathrooms_text_df, on=['neighbourhood_cleansed', 'property_type', 'accommodates'], how='left')\n",
    "\n",
    "# Fill missing bathrooms_text with the average (mode in this context)\n",
    "df['bathrooms_text'] = df['bathrooms_text'].fillna(df['average_bathrooms_text'])\n",
    "\n",
    "# Drop the average bathrooms_text column\n",
    "df = df.drop('average_bathrooms_text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the host_since column\n",
    "df['new_host'] = df['host_since'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Replace years less than 2024 with 0 and years greater than or equal to 2024 with 1\n",
    "df['new_host'] = df['new_host'].apply(lambda x: 0 if x < 2024 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['host_since'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prabh\\AppData\\Local\\Temp\\ipykernel_11520\\2672766150.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['host_response_time'] = df['host_response_time'].replace(\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping functions\n",
    "df['host_response_time'] = df['host_response_time'].replace(\n",
    "  [np.nan, 'within an hour', 'within a few hours', 'within a day', 'a few days or more'],\n",
    "  [0, 1, 2, 3, 4])\n",
    "\n",
    "def map_response_rate(rate):\n",
    "    if pd.isna(rate):\n",
    "        return 0\n",
    "    rate = int(str(rate).strip('%'))\n",
    "    if 90 <= rate <= 100:\n",
    "        return 4\n",
    "    elif 70 <= rate < 90:\n",
    "        return 3\n",
    "    elif 50 <= rate < 70:\n",
    "        return 2\n",
    "    elif 0 <= rate < 50:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def map_acceptance_rate(rate):\n",
    "    if pd.isna(rate):\n",
    "        return 0\n",
    "    rate = int(str(rate).strip('%'))\n",
    "    if 90 <= rate <= 100:\n",
    "        return 4\n",
    "    elif 70 <= rate < 90:\n",
    "        return 3\n",
    "    elif 50 <= rate < 70:\n",
    "        return 2\n",
    "    elif 0 <= rate < 50:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the mapping functions to the DataFrame\n",
    "\n",
    "df['host_response_rate'] = df['host_response_rate'].apply(map_response_rate)\n",
    "df['host_acceptance_rate'] = df['host_acceptance_rate'].apply(map_acceptance_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 3 columns to create the new column\n",
    "df['host_response_score'] = df['host_response_time'] + df['host_response_rate'] + df['host_acceptance_rate']\n",
    "\n",
    "# Dropping the 3 columns used for the addition\n",
    "df = df.drop(columns=['host_response_time', 'host_response_rate','host_acceptance_rate' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For host location, changing to binary column, with 0 as outside canada, and 1 as inside canada\n",
    "def within_canada(location):\n",
    "    if 'Canada' in str(location):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Applying the within canada function on host location\n",
    "df['host_location'] = df['host_location'].apply(within_canada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes t to 1 and f to 0 in host_is_superhost column\n",
    "df['host_is_superhost'] = df['host_is_superhost'].str.contains('t', na=False).astype(int)\n",
    "df['instant_bookable'] = df['instant_bookable'].str.contains('t', na=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping host_neighborhood and neighborhood columns, and keeping only neighborhood_cleansed column.\n",
    "df= df.drop(columns=['neighbourhood', 'host_neighbourhood'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping host_verifications column because it has not much importance in our predictions\n",
    "df= df.drop(columns=['host_verifications'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns to update with the 'contains text' logic\n",
    "columns_to_update = [\n",
    "    'host_has_profile_pic', \n",
    "    'host_identity_verified', \n",
    "    'host_about',\n",
    "    'neighborhood_overview',\n",
    "    'description'\n",
    "]\n",
    "\n",
    "# Iterate through each column in the list\n",
    "for column in columns_to_update:\n",
    "    # Apply a lambda function to each value in the column:\n",
    "    #   - If the value is truthy (i.e., not null, not empty string, not False) -> assign 1\n",
    "    #   - Otherwise (null, empty string, False) -> assign 0\n",
    "    df[column] = df[column].apply(lambda x: \n",
    "        # Check if the value is truthy (and not an empty string after stripping whitespace)\n",
    "        1 if x and str(x).strip() else 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 5 host related columns to create the new column host_score\n",
    "df['host_score'] = df['host_location'] + df['host_is_superhost'] + df['host_has_profile_pic'] + df['host_identity_verified'] + df['host_about']\n",
    "\n",
    "# Adding 2 property description related columns to create the new column property_description_score\n",
    "df['property_description_score'] = df['neighborhood_overview'] + df['description']\n",
    "\n",
    "# Dropping the 6 columns used for the addition\n",
    "df = df.drop(columns=['host_location','host_is_superhost', 'host_has_profile_pic','host_identity_verified', 'host_about',\n",
    "                      'neighborhood_overview' ,'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_matrix = df[['bathrooms', 'beds', 'bedrooms', 'accommodates']].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "#print(corr_matrix)\n",
    "\n",
    "df = df.drop(['room_type', 'source','bathrooms'], axis=1)\n",
    "#  'bedrooms', 'beds',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "property_type, room_type, accommodates, bathrooms, bathrooms_text, bedrooms, beds     \n",
    "If the model's accuracy score is low and any of these columns has high feature importance, we will come back and revisit the choice of columns, feature engg feature selection and encoding to further improve the model metrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that the columns number_of_reviews_l30d, number_of_reviews_ltm, reviews_per_month information overlaps with the number_of_reviews column so we will be dropping but if needed we will revisit to check if they can be used to improve the metrices.\n",
    "\n",
    "The columns first_reviews and last_review aren't that important to predict price but revisit if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['property_type', 'neighbourhood_cleansed'], axis=1)\n",
    "\n",
    "df = df.drop(['first_review', 'last_review', 'calendar_last_scraped', 'number_of_reviews_ltm',\n",
    "               'number_of_reviews_l30d', 'license','reviews_per_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_amenities'] = df['amenities'].apply(len)\n",
    "df['count_amenities'] = df['count_amenities'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248508 entries, 0 to 248507\n",
      "Data columns (total 29 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   id                              248508 non-null  int64  \n",
      " 1   host_id                         248508 non-null  int64  \n",
      " 2   neighbourhood_cleansed          248508 non-null  object \n",
      " 3   property_type                   248508 non-null  object \n",
      " 4   accommodates                    248508 non-null  int64  \n",
      " 5   bathrooms_text                  248376 non-null  float64\n",
      " 6   bedrooms                        246462 non-null  float64\n",
      " 7   beds                            248308 non-null  float64\n",
      " 8   amenities                       248508 non-null  object \n",
      " 9   price                           248470 non-null  float64\n",
      " 10  minimum_nights                  248508 non-null  int64  \n",
      " 11  maximum_nights                  248508 non-null  int64  \n",
      " 12  minimum_nights_avg_ntm          248508 non-null  float64\n",
      " 13  maximum_nights_avg_ntm          248508 non-null  float64\n",
      " 14  availability_30                 248508 non-null  int64  \n",
      " 15  availability_60                 248508 non-null  int64  \n",
      " 16  availability_90                 248508 non-null  int64  \n",
      " 17  availability_365                248508 non-null  int64  \n",
      " 18  number_of_reviews               248508 non-null  int64  \n",
      " 19  review_scores_rating            248508 non-null  float64\n",
      " 20  instant_bookable                248508 non-null  int32  \n",
      " 21  calculated_host_listings_count  248508 non-null  int64  \n",
      " 22  month                           248508 non-null  object \n",
      " 23  property                        248508 non-null  int8   \n",
      " 24  new_host                        248508 non-null  int64  \n",
      " 25  host_response_score             248508 non-null  int64  \n",
      " 26  host_score                      248508 non-null  int64  \n",
      " 27  property_description_score      248508 non-null  int64  \n",
      " 28  count_amenities                 248508 non-null  int32  \n",
      "dtypes: float64(7), int32(2), int64(15), int8(1), object(4)\n",
      "memory usage: 51.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert month column to the desired format (YYYY-MM-DD)\n",
    "df['month'] = pd.to_datetime(df['month'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['availability_365', 'availability_60', 'availability_90', 'host_id'], axis=1)\n",
    "#amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_year'] = df['month'].dt.year\n",
    "df['data_month'] = df['month'].dt.month\n",
    "\n",
    "# Drop the original datetime column\n",
    "df = df.drop(columns=['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['bedrooms','bathrooms_text', 'beds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'amenities' column has no NaN values\n",
    "df['amenities'] = df['amenities'].fillna('[]')\n",
    "\n",
    "# Parse the amenities column\n",
    "def parse_amenities(entry):\n",
    "    try:\n",
    "        # Use ast.literal_eval to safely parse the string to a list\n",
    "        amenities_list = ast.literal_eval(entry)\n",
    "        return amenities_list\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Handle parsing errors\n",
    "        return []\n",
    "#df.dropna(subset=['amenities_list'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_amenities(amenities_list):\n",
    "    normalized = []\n",
    "    for amenity in amenities_list:\n",
    "        amenity = amenity.lower().strip()\n",
    "        amenity = amenity.replace(' ', '_').replace('\"', '').replace(\"'\", '')\n",
    "        if 'translation_missing' not in amenity and amenity != '':\n",
    "            normalized.append(amenity)\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply parsing and normalization functions\n",
    "df['amenities_list'] = df['amenities'].apply(lambda x: normalize_amenities(parse_amenities(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df# Flatten the list of all amenities\n",
    "all_amenities = [amenity for sublist in df['amenities_list'] for amenity in sublist]\n",
    "\n",
    "# Count the occurrences of each amenity\n",
    "amenity_counts = Counter(all_amenities)\n",
    "\n",
    "# Calculate total number of listings\n",
    "total_listings = len(df)\n",
    "\n",
    "# Define frequency thresholds (e.g., between 5% and 95%)\n",
    "min_freq = 0.02\n",
    "max_freq = 0.98\n",
    "\n",
    "# Identify frequent amenities\n",
    "frequent_amenities = [\n",
    "    amenity for amenity, count in amenity_counts.items()\n",
    "    if min_freq <= (count / total_listings) <= max_freq\n",
    "]\n",
    "\n",
    "# Filter the amenities_list to keep only frequent amenities\n",
    "df['amenities_list'] = df['amenities_list'].apply(\n",
    "    lambda x: [amenity for amenity in x if amenity in frequent_amenities]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform the amenities_list\n",
    "amenities_encoded = mlb.fit_transform(df['amenities_list'])\n",
    "\n",
    "# Create a DataFrame with the encoded amenities\n",
    "amenities_df = pd.DataFrame(amenities_encoded, columns=mlb.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# Define the number of top amenities to select\n",
    "top_n = 100  # Adjust as needed\n",
    "\n",
    "# Initialize the selector with mutual_info_regression\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k=top_n)\n",
    "\n",
    "# Fit the selector to the data\n",
    "amenities_selected = selector.fit_transform(amenities_df, df['price'])\n",
    "\n",
    "# Get the indices of selected features\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected amenities\n",
    "selected_amenities = [mlb.classes_[i] for i in selected_indices]\n",
    "\n",
    "# Create a DataFrame with the selected amenities\n",
    "amenities_df_selected = amenities_df[selected_amenities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine with original data\n",
    "df = df.reset_index(drop=True)\n",
    "amenities_df_selected = amenities_df_selected.reset_index(drop=True)\n",
    "df = pd.concat([df, amenities_df_selected], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['amenities', 'amenities_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\prabh\\Downloads\\airbnb_project\\data\\listing_1_With_Amenities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
